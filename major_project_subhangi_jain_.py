# -*- coding: utf-8 -*-
"""Major Project Subhangi Jain .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tBwYTuLA01pox9kOXEfAVCz7tkoZr2_l
"""

#creating data drames from data set 
#univariate data set - 1 input 1 output 
#prediction of weight from height 
#dataset contains 2 features height in inches and weight in pounds 
import pandas as pd
df = pd.read_csv("https://gist.githubusercontent.com/nstokoe/7d4717e96c21b8ad04ec91f361b000cb/raw/bf95a2e30fceb9f2ae990eac8379fc7d844a0196/weight-height.csv")
df
df=df.drop(df.columns[[0]],axis=1) #done for the ease of handling data
df

#2. exploratory data analysis
df.info() # information about the dataframe like total entries , column name its datatype and null count in each features

df.shape #(no of rows * no of columns

df.size #shows total no of elemts of data set)

df.ndim #(to check dimension of array)

df.describe() #( gives descriptive statistics)

#3 data visualization 
import matplotlib.pyplot as plt

s= df["Height"].mean()
s

plt.hist(s)
plt.title("avg height of people ")
plt.xlabel("height in inches")
plt.show()

t=df["Weight"].mean()
t

plt.hist(t)
plt.title("avg weight of people ")
plt.ylabel("weight in inches")
plt.show()

#4 divide data in input and output 
#input is Height
#output is Weight
#var.iloc[row slicing,column slicing]

# selecting all rows of Height Column
x=df.iloc[:,0:1].values
x

#selecting all rows of Weight column
y=df.iloc[:,1].values
y

#5 train and test variable - only for multivariate data set

#6. normalisation done only for inputs if inputs are not scaled - only applicable for multivariate data set
#our data is already scaled because inputs are already scaled upto 6 digits of decimal places

#7. apply class8ifier?regressor?clusterer
from sklearn.linear_model import LinearRegression 
model=LinearRegression()
model

#8 fitting the model #mapping/plotting the inputs with the outputs  we are giving our data to LinearRegression library
model.fit(x,y)

#9 predicting output 
y_pred=model.predict(x)
y_pred

#10 actaul output values # in regression only linearlity is checked 
y

#conclusion - #compare predicted actual values with actual values 
#when we compare y_pred and y , there is a huge difference between the corresponding elements 
#this diff does not mean  outr model has predicted wrong , it means that our model is less linear or not linear 
#which depends on size and nature of the data

#individual prediction
#weight of 72 inches or 6 feet
model.predict([[72]])

#cross verify the result 
#y=mx+c
# to find m 
m=model.coef_
m

#y intercept
c=model.intercept_
c

#y=mx+c
m*72+c

#visualisation of best fit line
import matplotlib.pyplot as plt

plt.plot(x,y,color='khaki')#actual values
plt.plot(x,y_pred,color='blue')#predicted values 
plt.title("actual vs predicted values / best fit line")